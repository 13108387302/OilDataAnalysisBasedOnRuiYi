"""
åˆ†æä»»åŠ¡APIç«¯ç‚¹
å¤„ç†æœºå™¨å­¦ä¹ åˆ†æä»»åŠ¡çš„åˆ›å»ºå’Œæ‰§è¡Œ
æ³¨æ„ï¼šå·²ç§»é™¤æ‰€æœ‰æ¨¡æ‹Ÿæ•°æ®ï¼Œåªä½¿ç”¨çœŸå®æ•°æ®å’ŒçœŸå®æ¨¡å‹
"""

from fastapi import APIRouter
from typing import List, Optional, Dict, Any
import logging
from app.schemas.task import PredictRequest, TaskSubmitRequest
from pydantic import BaseModel, Field

# å®šä¹‰AnalysisRequestæ¨¡å‹
class AnalysisRequest(BaseModel):
    """
    åˆ†æä»»åŠ¡è¯·æ±‚æ¨¡å‹
    """
    task_name: str = Field(..., example="åˆ†æä»»åŠ¡")
    task_type: str = Field(..., example="analysis")
    algorithm: str = Field(..., example="linear_regression")
    features: List[str] = Field(..., example=["DEPTH", "GR"])
    target: str = Field(..., example="POROSITY")
    data_file: Optional[Dict[str, Any]] = Field(None, example={"name": "data.csv"})
    parameters: Optional[Dict[str, Any]] = Field(None, example={})

# é”™è¯¯ç å®šä¹‰
class ErrorCodes:
    SUCCESS = 200
    DEPENDENCY_MISSING = 1001
    ALGORITHM_NOT_IMPLEMENTED = 1002
    ALGORITHM_EXECUTION_FAILED = 1003
    TASK_PROCESSING_FAILED = 1004
    PREDICTION_FAILED = 1005
    BATCH_PREDICTION_FAILED = 1006
    INVALID_PARAMETERS = 1007
    FILE_NOT_FOUND = 1008
    MODEL_NOT_FOUND = 1009
    DATA_VALIDATION_FAILED = 1010


def check_ml_dependencies():
    """æ£€æŸ¥æœºå™¨å­¦ä¹ ä¾èµ–åŒ…ï¼Œè¿”å›é”™è¯¯å“åº”æˆ–None"""
    try:
        import sklearn
        import pandas as pd
        import numpy as np
        logging.info("âœ… æ£€æµ‹åˆ°æœºå™¨å­¦ä¹ ä¾èµ–åŒ…")
        return None
    except ImportError as e:
        missing_packages = []
        try:
            import sklearn  # noqa: F401
        except ImportError:
            missing_packages.append("scikit-learn")

        try:
            import pandas  # noqa: F401
        except ImportError:
            missing_packages.append("pandas")

        try:
            import numpy  # noqa: F401
        except ImportError:
            missing_packages.append("numpy")

        error_message = f"ç¼ºå°‘å¿…éœ€çš„æœºå™¨å­¦ä¹ ä¾èµ–åŒ…: {', '.join(missing_packages)}ã€‚è¯·å®‰è£…: pip install {' '.join(missing_packages)}"
        logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.DEPENDENCY_MISSING}] {error_message}")

        return create_error_response(
            error_code=ErrorCodes.DEPENDENCY_MISSING,
            message=error_message,
            missing_packages=missing_packages,
            installation_command=f"pip install {' '.join(missing_packages)}"
        )

# é”™è¯¯ä¿¡æ¯æ˜ å°„
ERROR_MESSAGES = {
    ErrorCodes.DEPENDENCY_MISSING: "ç¼ºå°‘å¿…éœ€çš„ä¾èµ–åŒ…",
    ErrorCodes.ALGORITHM_NOT_IMPLEMENTED: "ç®—æ³•æœªå®ç°",
    ErrorCodes.ALGORITHM_EXECUTION_FAILED: "ç®—æ³•æ‰§è¡Œå¤±è´¥",
    ErrorCodes.TASK_PROCESSING_FAILED: "ä»»åŠ¡å¤„ç†å¤±è´¥",
    ErrorCodes.PREDICTION_FAILED: "é¢„æµ‹æ‰§è¡Œå¤±è´¥",
    ErrorCodes.BATCH_PREDICTION_FAILED: "æ‰¹é‡é¢„æµ‹æ‰§è¡Œå¤±è´¥",
    ErrorCodes.INVALID_PARAMETERS: "å‚æ•°éªŒè¯å¤±è´¥",
    ErrorCodes.FILE_NOT_FOUND: "æ–‡ä»¶ä¸å­˜åœ¨",
    ErrorCodes.MODEL_NOT_FOUND: "æ¨¡å‹ä¸å­˜åœ¨",
    ErrorCodes.DATA_VALIDATION_FAILED: "æ•°æ®éªŒè¯å¤±è´¥"
}

def create_error_response(error_code: int, message: str = None, **kwargs):
    """åˆ›å»ºæ ‡å‡†é”™è¯¯å“åº”"""
    error_message = message or ERROR_MESSAGES.get(error_code, "æœªçŸ¥é”™è¯¯")
    return {
        "success": False,
        "error_code": error_code,
        "error": ERROR_MESSAGES.get(error_code, "æœªçŸ¥é”™è¯¯"),
        "message": error_message,
        "status": "failed",
        **kwargs
    }

def create_success_response(data: Any = None, message: str = "æ“ä½œæˆåŠŸ", **kwargs):
    """åˆ›å»ºæ ‡å‡†æˆåŠŸå“åº”"""
    return {
        "success": True,
        "error_code": ErrorCodes.SUCCESS,
        "message": message,
        "data": data,
        "status": "success",
        **kwargs
    }

def convert_profile_path(path: str) -> str:
    """
    è½¬æ¢/profile/è·¯å¾„ä¸ºå®é™…æ–‡ä»¶ç³»ç»Ÿè·¯å¾„
    /profile/xxx -> é¡¹ç›®æ ¹ç›®å½•/data/xxx
    """
    if not path:
        return path

    if path.startswith("/profile/"):
        import os
        relative_path = path[len("/profile/"):]

        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼šä»å½“å‰æ–‡ä»¶ä½ç½®å‘ä¸ŠæŸ¥æ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°åŒ…å«dataç›®å½•çš„ç›®å½•
        current_file = os.path.abspath(__file__)
        current_dir = os.path.dirname(current_file)

        # å‘ä¸ŠæŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•
        project_root = current_dir
        for _ in range(5):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾5çº§
            parent_dir = os.path.dirname(project_root)
            if parent_dir == project_root:  # å·²ç»åˆ°è¾¾æ ¹ç›®å½•
                break
            project_root = parent_dir

            # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†åŒ…å«dataç›®å½•çš„é¡¹ç›®æ ¹ç›®å½•
            data_dir = os.path.join(project_root, "data")
            if os.path.exists(data_dir):
                break

        converted_path = os.path.join(project_root, "data", relative_path).replace("\\", "/")

        logging.info(f"è·¯å¾„è½¬æ¢: {path} -> {converted_path}")
        logging.info(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
        return converted_path

    return path

def extract_data_file_path(data_file: dict) -> str:
    """
    ä»å‰ç«¯ä¼ é€’çš„data_fileå¯¹è±¡ä¸­æå–æ–‡ä»¶è·¯å¾„

    å‰ç«¯å¯èƒ½ä¼ é€’çš„å­—æ®µï¼š
    - path: ç›´æ¥è·¯å¾„
    - serverPath: æœåŠ¡å™¨è·¯å¾„
    - actualPath: å®é™…è·¯å¾„

    Args:
        data_file: å‰ç«¯ä¼ é€’çš„æ–‡ä»¶ä¿¡æ¯å­—å…¸

    Returns:
        è½¬æ¢åçš„æ–‡ä»¶è·¯å¾„
    """
    if not data_file:
        return ""

    # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„è·¯å¾„å­—æ®µ
    path_candidates = [
        data_file.get("path"),
        data_file.get("serverPath"),
        data_file.get("actualPath"),
        data_file.get("filePath")
    ]

    for path in path_candidates:
        if path:
            logging.info(f"ğŸ” æå–åˆ°æ•°æ®æ–‡ä»¶è·¯å¾„: {path}")
            return convert_profile_path(path)

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è·¯å¾„ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
    logging.error(f"âŒ æ— æ³•ä»data_fileä¸­æå–è·¯å¾„: {data_file}")
    return ""

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)

router = APIRouter()


@router.post("/submit")
async def submit_task(task_request: TaskSubmitRequest):
    """
    æäº¤ä»»åŠ¡ç«¯ç‚¹ - Javaåç«¯è°ƒç”¨çš„ä¸»è¦æ¥å£
    è°ƒç”¨å·²å®ç°çš„æœºå™¨å­¦ä¹ ç®—æ³•
    """
    try:
        logging.info(f"æ”¶åˆ°ä»»åŠ¡æäº¤è¯·æ±‚: {task_request.model_dump()}")

        # è®°å½•ä»»åŠ¡è¯¦ç»†ä¿¡æ¯
        logging.info(f"ä»»åŠ¡ID: {task_request.id}")
        logging.info(f"ä»»åŠ¡åç§°: {task_request.task_name}")
        logging.info(f"ç®—æ³•: {task_request.algorithm}")
        logging.info(f"è¾“å…¥æ–‡ä»¶: {task_request.input_file_path}")
        logging.info(f"è¾“å‡ºç›®å½•: {task_request.output_dir_path}")
        logging.info(f"å‚æ•°: {task_request.input_params}")

        # æ£€æŸ¥å¿…éœ€çš„ä¾èµ–åŒ…
        try:
            import sklearn
            import pandas as pd
            import numpy as np
            logging.info("âœ… æ£€æµ‹åˆ°æœºå™¨å­¦ä¹ ä¾èµ–åŒ…")

        except ImportError as e:
            missing_packages = []
            try:
                import sklearn  # noqa: F401
            except ImportError:
                missing_packages.append("scikit-learn")

            try:
                import pandas  # noqa: F401
            except ImportError:
                missing_packages.append("pandas")

            try:
                import numpy  # noqa: F401
            except ImportError:
                missing_packages.append("numpy")

            error_message = f"ç¼ºå°‘å¿…éœ€çš„æœºå™¨å­¦ä¹ ä¾èµ–åŒ…: {', '.join(missing_packages)}ã€‚è¯·å®‰è£…: pip install {' '.join(missing_packages)}"
            logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.DEPENDENCY_MISSING}] {error_message}")

            return create_error_response(
                error_code=ErrorCodes.DEPENDENCY_MISSING,
                message=error_message,
                task_id=task_request.id,
                task_name=task_request.task_name,
                algorithm=task_request.algorithm,
                missing_packages=missing_packages,
                installation_command=f"pip install {' '.join(missing_packages)}"
            )

        # è°ƒç”¨å·²å®ç°çš„ç®—æ³•
        try:
            from app.services.processor import run_task

            logging.info(f"å¼€å§‹æ‰§è¡Œç®—æ³•: {task_request.algorithm}")
            result = run_task(task_request)

            logging.info(f"âœ… ç®—æ³•æ‰§è¡ŒæˆåŠŸï¼Œä»»åŠ¡ID: {task_request.id}")
            return result

        except Exception as algorithm_error:
            error_message = f"ç®—æ³•æ‰§è¡Œå¤±è´¥: {str(algorithm_error)}"
            logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.ALGORITHM_EXECUTION_FAILED}] {error_message}", exc_info=True)

            return create_error_response(
                error_code=ErrorCodes.ALGORITHM_EXECUTION_FAILED,
                message=error_message,
                task_id=task_request.id,
                task_name=task_request.task_name,
                algorithm=task_request.algorithm,
                algorithm_error=True,
                details=str(algorithm_error)
            )

    except Exception as e:
        error_message = f"ä»»åŠ¡æäº¤å¤„ç†å¤±è´¥: {str(e)}"
        logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.TASK_PROCESSING_FAILED}] {error_message}", exc_info=True)

        return create_error_response(
            error_code=ErrorCodes.TASK_PROCESSING_FAILED,
            message=error_message,
            task_id=getattr(task_request, 'id', None),
            exception=True
        )



@router.post("/predict")
async def predict_data(predict_request: PredictRequest):
    """
    æ‰§è¡Œé¢„æµ‹ä»»åŠ¡
    ä½¿ç”¨å·²è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œé¢„æµ‹
    """
    try:
        logging.info(f"å¼€å§‹å¤„ç†é¢„æµ‹ä»»åŠ¡è¯·æ±‚: {predict_request.model_dump()}")

        # æ£€æŸ¥å¿…éœ€çš„ä¾èµ–åŒ…
        dependency_error = check_ml_dependencies()
        if dependency_error:
            return dependency_error

        # è°ƒç”¨é¢„æµ‹ç®—æ³•
        try:
            # æå–æ¨¡å‹è·¯å¾„
            model_path = None
            if predict_request.model_selection:
                if predict_request.model_selection.get("mode") == "existing":
                    # ä½¿ç”¨å·²æœ‰æ¨¡å‹
                    model_info = predict_request.model_selection.get("model", {})
                    raw_model_path = model_info.get("path")
                    if not raw_model_path:
                        raise ValueError("ä½¿ç”¨å·²æœ‰æ¨¡å‹æ—¶å¿…é¡»æä¾›æ¨¡å‹è·¯å¾„")

                    # è½¬æ¢è·¯å¾„æ ¼å¼ï¼š/profile/xxx -> ./data/xxx
                    model_path = convert_profile_path(raw_model_path)

                elif predict_request.model_selection.get("mode") == "algorithm":
                    # ä½¿ç”¨ç®—æ³•æ¨¡å¼ï¼Œéœ€è¦ä»ç®—æ³•åç§°æ¨æ–­æ¨¡å‹è·¯å¾„
                    algorithm = predict_request.model_selection.get("algorithm")
                    if algorithm:
                        # è¿™é‡Œå¯ä»¥æ ¹æ®ç®—æ³•åç§°æŸ¥æ‰¾å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
                        # æš‚æ—¶ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼Œå®é™…åº”è¯¥ä»æ•°æ®åº“æˆ–é…ç½®ä¸­è·å–
                        logging.warning(f"ç®—æ³•æ¨¡å¼æš‚æœªå®ç°æ¨¡å‹è·¯å¾„æŸ¥æ‰¾: {algorithm}")
                        raise ValueError(f"ç®—æ³•æ¨¡å¼ '{algorithm}' çš„æ¨¡å‹è·¯å¾„æŸ¥æ‰¾åŠŸèƒ½å°šæœªå®ç°")

            if not model_path:
                raise ValueError("é¢„æµ‹ä»»åŠ¡å¿…é¡»æŒ‡å®šæ¨¡å‹è·¯å¾„")

            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            import os
            logging.info(f"ğŸ” æ£€æŸ¥æ¨¡å‹æ–‡ä»¶: {model_path}")
            logging.info(f"ğŸ” å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
            logging.info(f"ğŸ” æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(model_path)}")

            if not os.path.exists(model_path):
                # å°è¯•åˆ—å‡ºç›®å½•å†…å®¹ä»¥å¸®åŠ©è°ƒè¯•
                dir_path = os.path.dirname(model_path)
                if os.path.exists(dir_path):
                    files = os.listdir(dir_path)
                    logging.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                    logging.error(f"ğŸ“ ç›®å½• {dir_path} ä¸­çš„æ–‡ä»¶: {files}")
                else:
                    logging.error(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {dir_path}")
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

            logging.info(f"âœ… ä½¿ç”¨æ¨¡å‹è·¯å¾„: {model_path}")

            # æ„å»ºé¢„æµ‹ä»»åŠ¡è¯·æ±‚
            from app.schemas.task import TaskSubmitRequest

            # å°†PredictRequestè½¬æ¢ä¸ºTaskSubmitRequestæ ¼å¼
            task_request = TaskSubmitRequest(
                id=0,  # é¢„æµ‹ä»»åŠ¡ä½¿ç”¨ä¸´æ—¶ID
                task_name=predict_request.task_name,
                task_type=predict_request.task_type,
                algorithm=f"{predict_request.task_type}_{predict_request.model_selection.get('algorithm', 'linear')}_predict",
                input_params={
                    "model_path": model_path,  # æ·»åŠ æ¨¡å‹è·¯å¾„
                    "feature_columns": predict_request.features,  # ä½¿ç”¨feature_columnsè€Œä¸æ˜¯features
                    "target": predict_request.target,
                    "model_selection": predict_request.model_selection,
                    "parameters": predict_request.parameters or {},
                    "prediction_indices": predict_request.prediction_indices,
                    "sample_count": predict_request.sample_count,
                    "sampling_strategy": predict_request.sampling_strategy,
                    "output_precision": predict_request.output_precision,
                    "include_confidence": predict_request.include_confidence,
                    "include_input_features": predict_request.include_input_features,
                    "output_format": predict_request.output_format
                },
                input_file_path=extract_data_file_path(predict_request.data_file),
                output_dir_path="/tmp/prediction_output"
            )

            from app.services.processor import run_task

            logging.info(f"å¼€å§‹æ‰§è¡Œé¢„æµ‹ç®—æ³•: {task_request.algorithm}")
            result = run_task(task_request)

            logging.info(f"âœ… é¢„æµ‹ç®—æ³•æ‰§è¡ŒæˆåŠŸ")
            return create_success_response(
                data=result,
                message="é¢„æµ‹æ‰§è¡ŒæˆåŠŸ",
                task_name=predict_request.task_name,
                features=predict_request.features,
                target=predict_request.target
            )

        except Exception as algorithm_error:
            error_message = f"é¢„æµ‹ç®—æ³•æ‰§è¡Œå¤±è´¥: {str(algorithm_error)}"
            logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.PREDICTION_FAILED}] {error_message}", exc_info=True)

            return create_error_response(
                error_code=ErrorCodes.PREDICTION_FAILED,
                message=error_message,
                task_name=predict_request.task_name,
                algorithm_error=True,
                details=str(algorithm_error)
            )

    except Exception as e:
        error_message = f"é¢„æµ‹ä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}"
        logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.PREDICTION_FAILED}] {error_message}", exc_info=True)

        return create_error_response(
            error_code=ErrorCodes.PREDICTION_FAILED,
            message=error_message,
            exception=True
        )


@router.post("/batch-predict")
async def batch_predict_data(batch_request: Dict[str, Any]):
    """
    æ‰§è¡Œæ‰¹é‡é¢„æµ‹ä»»åŠ¡
    ä½¿ç”¨å·²è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œæ‰¹é‡é¢„æµ‹
    """
    try:
        logging.info(f"å¼€å§‹å¤„ç†æ‰¹é‡é¢„æµ‹ä»»åŠ¡è¯·æ±‚: {batch_request}")

        # æ£€æŸ¥å¿…éœ€çš„ä¾èµ–åŒ…
        dependency_error = check_ml_dependencies()
        if dependency_error:
            return dependency_error

        # è°ƒç”¨æ‰¹é‡é¢„æµ‹ç®—æ³•
        try:
            from app.schemas.task import TaskSubmitRequest

            # æ„å»ºæ‰¹é‡é¢„æµ‹ä»»åŠ¡è¯·æ±‚
            task_request = TaskSubmitRequest(
                id=0,  # æ‰¹é‡é¢„æµ‹ä»»åŠ¡ä½¿ç”¨ä¸´æ—¶ID
                task_name=batch_request.get("task_name", "æ‰¹é‡é¢„æµ‹ä»»åŠ¡"),
                task_type=batch_request.get("task_type", "batch_prediction"),
                algorithm=batch_request.get("algorithm", "batch_predict"),
                input_params=batch_request.get("input_params", {}),
                input_file_path=batch_request.get("input_file_path", ""),
                output_dir_path=batch_request.get("output_dir_path", "/tmp/batch_prediction_output")
            )

            from app.services.processor import run_task

            logging.info(f"å¼€å§‹æ‰§è¡Œæ‰¹é‡é¢„æµ‹ç®—æ³•: {task_request.algorithm}")
            result = run_task(task_request)

            logging.info(f"âœ… æ‰¹é‡é¢„æµ‹ç®—æ³•æ‰§è¡ŒæˆåŠŸ")
            return create_success_response(
                data=result,
                message="æ‰¹é‡é¢„æµ‹æ‰§è¡ŒæˆåŠŸ",
                batch_info=batch_request
            )

        except Exception as algorithm_error:
            error_message = f"æ‰¹é‡é¢„æµ‹ç®—æ³•æ‰§è¡Œå¤±è´¥: {str(algorithm_error)}"
            logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.BATCH_PREDICTION_FAILED}] {error_message}", exc_info=True)

            return create_error_response(
                error_code=ErrorCodes.BATCH_PREDICTION_FAILED,
                message=error_message,
                algorithm_error=True,
                details=str(algorithm_error)
            )

    except Exception as e:
        error_message = f"æ‰¹é‡é¢„æµ‹ä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}"
        logging.error(f"âŒ [é”™è¯¯ç :{ErrorCodes.BATCH_PREDICTION_FAILED}] {error_message}", exc_info=True)

        return create_error_response(
            error_code=ErrorCodes.BATCH_PREDICTION_FAILED,
            message=error_message,
            exception=True
        )


@router.get("/health")
async def health_check():
    """
    å¥åº·æ£€æŸ¥ç«¯ç‚¹
    """
    return {
        "status": "healthy",
        "message": "åˆ†ææœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œå·²é›†æˆçœŸå®æœºå™¨å­¦ä¹ ç®—æ³•",
        "mock_data_removed": True,
        "real_algorithms_enabled": True,
        "available_algorithms": [
            "regression_linear_train",
            "regression_polynomial_train",
            "regression_random_forest_train",
            "classification_logistic_train",
            "clustering_kmeans_train",
            "feature_engineering_automatic_regression_train"
        ]
    }


# è¾…åŠ©å‡½æ•°ï¼šéªŒè¯æ•°æ®æ–‡ä»¶
def validate_data_file(data_file_info: Dict[str, Any]) -> bool:
    """
    éªŒè¯æ•°æ®æ–‡ä»¶ä¿¡æ¯çš„æœ‰æ•ˆæ€§
    """
    if not data_file_info:
        return False
    
    required_fields = ['name', 'path']
    for field in required_fields:
        if field not in data_file_info:
            logging.warning(f"æ•°æ®æ–‡ä»¶ä¿¡æ¯ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            return False
    
    return True


# è¾…åŠ©å‡½æ•°ï¼šéªŒè¯ç‰¹å¾åˆ—
def validate_features(features: List[str], target: str) -> bool:
    """
    éªŒè¯ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—çš„æœ‰æ•ˆæ€§
    """
    if not features:
        logging.error("ç‰¹å¾åˆ—åˆ—è¡¨ä¸ºç©º")
        return False
    
    if not target:
        logging.error("ç›®æ ‡åˆ—ä¸ºç©º")
        return False
    
    if target in features:
        logging.error(f"ç›®æ ‡åˆ— '{target}' ä¸èƒ½åŒæ—¶ä½œä¸ºç‰¹å¾åˆ—")
        return False
    
    return True


# è¾…åŠ©å‡½æ•°ï¼šè®°å½•è¯·æ±‚ä¿¡æ¯
def log_request_info(request_type: str, request_data: Dict[str, Any]):
    """
    è®°å½•è¯·æ±‚çš„è¯¦ç»†ä¿¡æ¯
    """
    logging.info(f"=== {request_type} è¯·æ±‚è¯¦æƒ… ===")
    logging.info(f"ä»»åŠ¡åç§°: {request_data.get('task_name', 'N/A')}")
    logging.info(f"ä»»åŠ¡ç±»å‹: {request_data.get('task_type', 'N/A')}")
    logging.info(f"ç‰¹å¾åˆ—: {request_data.get('features', [])}")
    logging.info(f"ç›®æ ‡åˆ—: {request_data.get('target', 'N/A')}")
    
    if 'data_file' in request_data:
        logging.info(f"æ•°æ®æ–‡ä»¶: {request_data['data_file']}")
    
    logging.info("=== è¯·æ±‚è¯¦æƒ…ç»“æŸ ===")
